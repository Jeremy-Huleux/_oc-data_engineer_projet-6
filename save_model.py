import bentoml
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import make_column_transformer
from sklearn.pipeline import make_pipeline

# --- 1. S√âLECTION DES DONN√âES (TOP 5) ---
# On reprend la strat√©gie TOP 5 : moins de variables = plus simple pour l'API
features_top_5 = [
    'PropertyGFATotal',
    'ENERGYSTARScore',
    'BuildingAge',
    'BuildingType',
    'Neighborhood'
]

# R√©cup√©ration du csv
try:
    df_final = pd.read_csv("data_cleaned_final.csv")
    print(f"Donn√©es charg√©es : {df_final.shape}")
except FileNotFoundError:
    print("ERREUR : Le fichier 'data_cleaned_final.csv' est introuvable.")
    print("Avez-vous bien fait l'export to_csv() dans notebook ?")
    exit()

df_final['Neighborhood'] = df_final['Neighborhood'].str.upper()
X = df_final[features_top_5]
y = np.log1p(df_final['SiteEnergyUse(kBtu)']) # On n'oublie pas le Log !

# Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# --- 2. CONSTRUCTION DU PIPELINE (LE TUNNEL) ---

# Le Morceau A : Le Trieur (Preprocessor)
preprocessor = make_column_transformer(
    (OneHotEncoder(handle_unknown='ignore', sparse_output=False), ['BuildingType', 'Neighborhood']),
    (StandardScaler(), ['PropertyGFATotal', 'ENERGYSTARScore', 'BuildingAge'])
)

# Le Tunnel Complet : Random Forest optimis√©
# On reprend les meilleurs hyperparam√®tres trouv√©s tout √† l'heure gr√¢ce a GridSearch
model_pipeline = make_pipeline(
    preprocessor,
    RandomForestRegressor(
        n_estimators=200,      # Confirm√© par GridSearch
        max_depth=10,          # Confirm√© par GridSearch
        min_samples_leaf=4,    # Confirm√© par GridSearch
        random_state=42
    )
)

# --- 3. ENTR√ÇINEMENT (.fit) ---
print("Entra√Ænement du Pipeline en cours...")
model_pipeline.fit(X_train, y_train)
print("Pipeline entra√Æn√© avec succ√®s ! ‚úÖ")

# --- 4. SAUVEGARDE DANS BENTOML üç± ---
# On sauvegarde tout le pipeline d'un coup.
# Pas besoin de s√©parer le preprocessor.

saved_model = bentoml.sklearn.save_model(
    "seattle_energy_pipeline",  # Le nom de l'API
    model_pipeline,             # On sauvegarde le tunnel entier
    signatures={
        "predict": {"batchable": False}
    }
)

print(f"Mod√®le sauvegard√© : {saved_model}")